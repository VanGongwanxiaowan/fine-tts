# Fine-tuning a ğŸ¸ TTS model 

å¾®è°ƒä¸€ä¸ªğŸ¸TTSæ¨¡å‹

Fine-tuning takes a pre-trained model and retrains it to improve the model performance on a different task or dataset. In ğŸ¸TTS we provide different pre-trained models in different languages and different pros and cons. You can take one of them and fine-tune it for your own dataset. This will help you in two main ways:


å¾®è°ƒæ˜¯æŒ‡è·å–ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹å¹¶å¯¹å…¶é‡æ–°è®­ç»ƒï¼Œä»¥æé«˜æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡æˆ–æ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚åœ¨ğŸ¸TTSä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸åŒè¯­è¨€çš„å„ç§é¢„è®­ç»ƒæ¨¡å‹ï¼Œå®ƒä»¬å„æœ‰ä¼˜ç¼ºç‚¹ã€‚ä½ å¯ä»¥é€‰æ‹©å…¶ä¸­ä¸€ä¸ªï¼Œé’ˆå¯¹è‡ªå·±çš„æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚è¿™å°†åœ¨ä¸¤ä¸ªä¸»è¦æ–¹é¢ä¸ºä½ æä¾›å¸®åŠ©ï¼š


1.Faster learning æ›´å¿«çš„å­¦ä¹ é€Ÿåº¦

Since a pre-trained model has already learned features that are relevant for the task, it will converge faster on a new dataset. This will reduce the cost of training and let you experiment faster.

ç”±äºé¢„è®­ç»ƒæ¨¡å‹å·²ç»å­¦ä¹ äº†ä¸ä»»åŠ¡ç›¸å…³çš„ç‰¹å¾ï¼Œå®ƒåœ¨æ–°æ•°æ®é›†ä¸Šçš„æ”¶æ•›é€Ÿåº¦ä¼šæ›´å¿«ã€‚è¿™å°†é™ä½è®­ç»ƒæˆæœ¬ï¼Œå¹¶è®©ä½ èƒ½æ›´å¿«åœ°è¿›è¡Œå®éªŒã€‚

2.Better results with small datasets å°æ•°æ®é›†ä¹Ÿèƒ½æœ‰æ›´å¥½çš„ç»“æœ


Deep learning models are data hungry and they give better performance with more data. However, it is not always possible to have this abundance, especially in specific domains. For instance, the LJSpeech dataset, that we released most of our English models with, is almost 24 hours long. It takes weeks to record this amount of data with the help of a voice actor.

æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹æ•°æ®çš„éœ€æ±‚é‡å¾ˆå¤§ï¼Œæ•°æ®è¶Šå¤šï¼Œå…¶æ€§èƒ½å°±è¶Šå¥½ã€‚ç„¶è€Œï¼Œå¹¶éæ€»èƒ½è·å¾—å¦‚æ­¤å¤§é‡çš„æ•°æ®ï¼Œå°¤å…¶æ˜¯åœ¨ç‰¹å®šé¢†åŸŸã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å‘å¸ƒçš„å¤§å¤šæ•°è‹±è¯­æ¨¡å‹æ‰€ä½¿ç”¨çš„LJSpeechæ•°æ®é›†ï¼Œæ—¶é•¿æ¥è¿‘24å°æ—¶ã€‚åœ¨é…éŸ³æ¼”å‘˜çš„ååŠ©ä¸‹ï¼Œå½•åˆ¶è¿™ä¹ˆå¤šæ•°æ®éœ€è¦æ•°å‘¨æ—¶é—´ã€‚

Fine-tuning comes to the rescue in this case. You can take one of our pre-trained models and fine-tune it on your own speech dataset and achieve reasonable results with only a couple of hours of data.

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¾®è°ƒå°±èƒ½æ´¾ä¸Šç”¨åœºäº†ã€‚ä½ å¯ä»¥é€‰ç”¨æˆ‘ä»¬çš„ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œç”¨ä½ è‡ªå·±çš„è¯­éŸ³æ•°æ®é›†å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œä»…ç”¨å‡ ä¸ªå°æ—¶çš„æ•°æ®å°±èƒ½å–å¾—ä¸é”™çš„ç»“æœã€‚

However, note that, fine-tuning does not ensure great results. The model performance still depends on the dataset quality and the hyper-parameters you choose for fine-tuning. Therefore, it still takes a bit of tinkering.

ç„¶è€Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¾®è°ƒå¹¶ä¸èƒ½ä¿è¯è‰¯å¥½çš„ç»“æœã€‚æ¨¡å‹æ€§èƒ½ä»ç„¶å–å†³äºæ•°æ®é›†è´¨é‡ä»¥åŠä½ ä¸ºå¾®è°ƒé€‰æ‹©çš„è¶…å‚æ•°ã€‚å› æ­¤ï¼Œè¿™ä»ç„¶éœ€è¦ä¸€äº›è°ƒæ•´ã€‚

# Steps to fine-tune a ğŸ¸ TTS model

å¾®è°ƒğŸ¸TTSæ¨¡å‹çš„æ­¥éª¤

1.Setup your dataset. è®¾ç½®ä½ çš„æ•°æ®é›†ã€‚

You need to format your target dataset in a certain way so that ğŸ¸TTS data loader will be able to load it for the training. Please see this page for more information about formatting.

ä½ éœ€è¦å°†ç›®æ ‡æ•°æ®é›†æŒ‰ç…§ç‰¹å®šæ ¼å¼è¿›è¡Œå¤„ç†ï¼Œä»¥ä¾¿ğŸ¸TTSæ•°æ®åŠ è½½å™¨èƒ½å¤ŸåŠ è½½å®ƒç”¨äºè®­ç»ƒã€‚æœ‰å…³æ ¼å¼è®¾ç½®çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§æœ¬é¡µã€‚

2.Choose the model you want to fine-tune.

é€‰æ‹©ä½ æƒ³è¦å¾®è°ƒçš„æ¨¡å‹ã€‚

You can list the available models in the command line with

ä½ å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œåˆ—å‡ºå¯ç”¨çš„æ¨¡å‹ï¼Œæ–¹æ³•æ˜¯ä½¿ç”¨

```
tts --list_models
```

The command above lists the models in a naming format as <model_type>/<language>/<dataset>/<model_name>.

ä¸Šé¢çš„å‘½ä»¤ä»¥<model_type>/<language>/<dataset>/<model_name>çš„å‘½åæ ¼å¼åˆ—å‡ºæ¨¡å‹ã€‚


Or you can manually check the .model.json file in the project directory.

æˆ–è€…ä½ å¯ä»¥æ‰‹åŠ¨æ£€æŸ¥é¡¹ç›®ç›®å½•ä¸­çš„.model.jsonæ–‡ä»¶ã€‚

You should choose the model based on your requirements. Some models are fast and some are better in speech quality. One lazy way to test a model is running the model on the hardware you want to use and see how it works. For simple testing, you can use the tts command on the terminal. For more info see here.

ä½ åº”è¯¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚é€‰æ‹©æ¨¡å‹ã€‚æœ‰äº›æ¨¡å‹é€Ÿåº¦å¿«ï¼Œæœ‰äº›åˆ™åœ¨è¯­éŸ³è´¨é‡ä¸Šæ›´å‡ºè‰²ã€‚ä¸€ç§ç®€å•çš„æµ‹è¯•æ¨¡å‹çš„æ–¹æ³•æ˜¯åœ¨ä½ æƒ³è¦ä½¿ç”¨çš„ç¡¬ä»¶ä¸Šè¿è¡Œè¯¥æ¨¡å‹ï¼Œçœ‹çœ‹å®ƒçš„è¡¨ç°å¦‚ä½•ã€‚å¯¹äºç®€å•æµ‹è¯•ï¼Œä½ å¯ä»¥åœ¨ç»ˆç«¯ä¸Šä½¿ç”¨ttså‘½ä»¤ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è§æ­¤å¤„ã€‚

3.Download the model. ä¸‹è½½æ¨¡å‹ã€‚

You can download the model by using the tts command. If you run tts with a particular model, it will download it automatically and the model path will be printed on the terminal.

ä½ å¯ä»¥ä½¿ç”¨ttså‘½ä»¤ä¸‹è½½è¯¥æ¨¡å‹ã€‚å¦‚æœä½ ä½¿ç”¨ç‰¹å®šæ¨¡å‹è¿è¡Œttsï¼Œå®ƒä¼šè‡ªåŠ¨ä¸‹è½½è¯¥æ¨¡å‹ï¼Œå¹¶ä¸”æ¨¡å‹è·¯å¾„ä¼šæ˜¾ç¤ºåœ¨ç»ˆç«¯ä¸Šã€‚

```
tts --model_name tts_models/es/mai/tacotron2-DDC --text "Ola."

> Downloading model to /home/ubuntu/.local/share/tts/tts_models--en--ljspeech--glow-tts
...
```

In the example above, we called the Spanish Tacotron model and give the sample output showing use the path where the model is downloaded.

åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬è°ƒç”¨äº†è¥¿ç­ç‰™è¯­Tacotronæ¨¡å‹ï¼Œå¹¶ç»™å‡ºäº†ç¤ºä¾‹è¾“å‡ºï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨æ¨¡å‹ä¸‹è½½çš„è·¯å¾„ã€‚

4.Setup the model config for fine-tuning.
è®¾ç½®ç”¨äºå¾®è°ƒçš„æ¨¡å‹é…ç½®ã€‚

You need to change certain fields in the model config. You have 3 options for playing with the configuration.

ä½ éœ€è¦ä¿®æ”¹æ¨¡å‹é…ç½®ä¸­çš„æŸäº›å­—æ®µã€‚ä½ æœ‰3ç§æ–¹å¼å¯ä»¥è°ƒæ•´è¯¥é…ç½®ã€‚

1.Edit the fields in the config.json file if you want to use TTS/bin/train_tts.py to train the model.

å¦‚æœæ‚¨æƒ³ä½¿ç”¨TTS/bin/train_tts.pyæ¥è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç¼–è¾‘config.jsonæ–‡ä»¶ä¸­çš„å­—æ®µã€‚

2.Edit the fields in one of the training scripts in the recipes directory if you want to use python.

å¦‚æœæ‚¨æƒ³ä½¿ç”¨pythonï¼Œè¯·ç¼–è¾‘recipesç›®å½•ä¸­æŸä¸ªè®­ç»ƒè„šæœ¬é‡Œçš„å­—æ®µã€‚

3.Use the command-line arguments to override the fields like --coqpit.lr 0.00001 to change the learning rate.

ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æ¥è¦†ç›–å­—æ®µï¼Œä¾‹å¦‚--coqpit.lr 0.00001ä»¥æ›´æ”¹å­¦ä¹ ç‡ã€‚

Some of the important fields are as follows:

ä¸€äº›é‡è¦çš„å­—æ®µå¦‚ä¸‹ï¼š

datasets field: This is set to the dataset you want to fine-tune the model on.

datasetså­—æ®µï¼šè¿™è¢«è®¾ç½®ä¸ºä½ æƒ³è¦ç”¨äºå¾®è°ƒæ¨¡å‹çš„æ•°æ®é›†ã€‚


run_name field: This is the name of the run. This is used to name the output directory and the entry in the logging dashboard.

run_nameå­—æ®µï¼šè¿™æ˜¯è¿è¡Œçš„åç§°ã€‚å®ƒç”¨äºå‘½åè¾“å‡ºç›®å½•ä»¥åŠæ—¥å¿—ä»ªè¡¨æ¿ä¸­çš„æ¡ç›®ã€‚

output_path field: This is the path where the fine-tuned model is saved.

output_pathå­—æ®µï¼šè¿™æ˜¯ä¿å­˜å¾®è°ƒæ¨¡å‹çš„è·¯å¾„ã€‚

lr field: You may need to use a smaller learning rate for fine-tuning to not lose the features learned by the pre-trained model with big update steps.

lrå­—æ®µï¼šåœ¨å¾®è°ƒæ—¶ï¼Œä½ å¯èƒ½éœ€è¦ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡ï¼Œä»¥é¿å…å› è¾ƒå¤§çš„æ›´æ–°æ­¥éª¤è€Œä¸¢å¤±é¢„è®­ç»ƒæ¨¡å‹å­¦åˆ°çš„ç‰¹å¾ã€‚


audio fields: Different datasets have different audio characteristics. You must check the current audio parameters and make sure that the values reflect your dataset. For instance, your dataset might have a different audio sampling rate.

audioå­—æ®µï¼šä¸åŒçš„æ•°æ®é›†å…·æœ‰ä¸åŒçš„éŸ³é¢‘ç‰¹å¾ã€‚ä½ å¿…é¡»æ£€æŸ¥å½“å‰çš„éŸ³é¢‘å‚æ•°ï¼Œå¹¶ç¡®ä¿è¿™äº›å€¼èƒ½åæ˜ ä½ çš„æ•°æ®é›†ã€‚ä¾‹å¦‚ï¼Œä½ çš„æ•°æ®é›†å¯èƒ½å…·æœ‰ä¸åŒçš„éŸ³é¢‘é‡‡æ ·ç‡ã€‚

Apart from the parameters above, you should check the whole configuration file and make sure that the values are correct for your dataset and training.

é™¤äº†ä¸Šè¿°å‚æ•°å¤–ï¼Œä½ è¿˜åº”æ£€æŸ¥æ•´ä¸ªé…ç½®æ–‡ä»¶ï¼Œç¡®ä¿å…¶ä¸­çš„å€¼å¯¹äºä½ çš„æ•°æ®é›†å’Œè®­ç»ƒæ˜¯æ­£ç¡®çš„


5.Start fine-tuning. å¼€å§‹å¾®è°ƒã€‚

Whether you use one of the training scripts under recipes folder or the train_tts.py to start your training, you should use the --restore_path flag to specify the path to the pre-trained model.

æ— è®ºä½ æ˜¯ä½¿ç”¨recipesæ–‡ä»¶å¤¹ä¸‹çš„è®­ç»ƒè„šæœ¬ä¹‹ä¸€ï¼Œè¿˜æ˜¯ä½¿ç”¨train_tts.pyæ¥å¼€å§‹è®­ç»ƒï¼Œéƒ½åº”è¯¥ä½¿ç”¨--restore_pathæ ‡å¿—æ¥æŒ‡å®šé¢„è®­ç»ƒæ¨¡å‹çš„è·¯å¾„ã€‚

```
CUDA_VISIBLE_DEVICES="0" python recipes/ljspeech/glow_tts/train_glowtts.py \
    --restore_path  /home/ubuntu/.local/share/tts/tts_models--en--ljspeech--glow-tts/model_file.pth

CUDA_VISIBLE_DEVICES="0" python TTS/bin/train_tts.py \
    --config_path  /home/ubuntu/.local/share/tts/tts_models--en--ljspeech--glow-tts/config.json \
    --restore_path  /home/ubuntu/.local/share/tts/tts_models--en--ljspeech--glow-tts/model_file.pth
```

As stated above, you can also use command-line arguments to change the model configuration.

å¦‚ä¸Šæ‰€è¿°ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æ¥æ›´æ”¹æ¨¡å‹é…ç½®ã€‚

```
CUDA_VISIBLE_DEVICES="0" python recipes/ljspeech/glow_tts/train_glowtts.py \
    --restore_path  /home/ubuntu/.local/share/tts/tts_models--en--ljspeech--glow-tts/model_file.pth
    --coqpit.run_name "glow-tts-finetune" \
    --coqpit.lr 0.00001
```






